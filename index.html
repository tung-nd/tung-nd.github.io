<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Tung Nguyen </title> <meta name="author" content="Tung Nguyen"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/tung.jpg?6fff9899ecb2912054ac27b0e30a57a6"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tung-nd.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Tung</span> Nguyen </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/tung-480.webp 480w,/assets/img/tung-800.webp 800w,/assets/img/tung-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/tung.jpg?6fff9899ecb2912054ac27b0e30a57a6" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="tung.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>I’m a fourth-year PhD candidate in Computer Science at UCLA, advised by <a href="https://aditya-grover.github.io/" rel="external nofollow noopener" target="_blank">Aditya Grover</a>. I earned my Bachelor’s degree in Computer Science from the Hanoi University of Science and Technology. Prior to my PhD, I spent two wonderful years at VinAI Research as an AI Resident, where I had the privilege of working under the supervision of <a href="https://sites.google.com/site/buihhung/" rel="external nofollow noopener" target="_blank">Hung Bui</a> and collaborating with amazing colleagues like <a href="https://ruishu.io/" rel="external nofollow noopener" target="_blank">Rui Shu</a> and <a href="https://scholar.google.com/citations?user=CmbSBmQAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Tuan Pham</a>.</p> <p>I’m always open to collaborations, discussions, and new opportunities. Feel free to reach out if you’re interested in my research or would like to discuss potential projects.</p> <p><strong>Research:</strong> My research focuses on building large-scale foundation models to support scientific discovery, particularly in areas related to climate change, sustainability, and the physical sciences.</p> <p><strong>1. AI for Scientific Simulation.</strong> I develop machine learning models to simulate real-world phenomena such as weather and climate dynamics using large-scale scientific datasets. These models aim to be accurate, adaptable, and capable of representing uncertainty in complex systems.</p> <p><strong>2. AI for Experimental Design.</strong> I also work on using AI to solve optimization problems in scientific and engineering domains, such as molecular design and drug discovery. My goal is to build generalizable models that can perform across tasks with limited supervision, offering efficient and robust tools for real-world scientific discovery.</p> </div> <h2> <a href="/news/" style="color: inherit">Recent News</a> </h2> <div class="news"> <ul> <li> <a href="https://arxiv.org/abs/2406.18851" rel="external nofollow noopener" target="_blank">LICO</a> got accepted at ICLR 2025. </li> <li> Honored to receive the <strong>Outstanding Graduate Student Research Award</strong>, Department of Computer Science, UCLA. </li> <li> <a href="https://arxiv.org/abs/2312.03876" rel="external nofollow noopener" target="_blank">Stormer</a>, <a href="https://arxiv.org/abs/2402.00712" rel="external nofollow noopener" target="_blank">ChaosBench</a>, and <a href="https://arxiv.org/abs/2406.11233v1" rel="external nofollow noopener" target="_blank">Probing LLM</a> got accepted at NeurIPS 2024. Probing LLM won the <strong>best paper award</strong> at the Foundation Model Interventions Workshop, NeurIPS 2024. </li> <li> <a href="https://arxiv.org/abs/2312.03876" rel="external nofollow noopener" target="_blank">Stormer</a> won the <strong>best paper award</strong> at the Climate Change in AI (CCAI) Workshop at ICLR 2024. </li> <li> We released <a href="https://arxiv.org/abs/2312.03876" rel="external nofollow noopener" target="_blank">Stormer</a>, which achieves state-of-the-art performance for data-driven weather forecasting. </li> <li> <a href="https://arxiv.org/abs/2310.19961" rel="external nofollow noopener" target="_blank">ExPT</a> and <a href="https://arxiv.org/abs/2307.01909" rel="external nofollow noopener" target="_blank">ClimateLearn</a> got accepted at NeurIPS 2023. </li> <li> Presented <a href="https://arxiv.org/abs/2301.10343" rel="external nofollow noopener" target="_blank">ClimaX</a> at <a href="https://www.agu.org/annual-meeting" rel="external nofollow noopener" target="_blank">AGU Fall Meeting 2023</a>, <a href="https://ai4climatescience.github.io/" rel="external nofollow noopener" target="_blank">AI4ClimateScience at AAAI 2023</a>, <a href="https://ai4er-cdt.esc.cam.ac.uk/" rel="external nofollow noopener" target="_blank">University of Cambridge AI4ER Seminar Series</a>, <a href="http://www.bom.gov.au/" rel="external nofollow noopener" target="_blank">Bureau of Meteorology – Australia</a>, <a href="https://sciml-leeds.github.io/" rel="external nofollow noopener" target="_blank">University of Leeds</a>, <a href="https://www.uga.edu/" rel="external nofollow noopener" target="_blank">University of Georgia</a>, and <a href="https://www.utk.edu/" rel="external nofollow noopener" target="_blank">University of Tennessee</a>. </li> <li> <a href="https://arxiv.org/abs/2301.10343" rel="external nofollow noopener" target="_blank">ClimaX</a> got accepted at ICML 2023 and won the <strong>best paper award</strong> at the <a href="https://syns-ml.github.io/2023/cfsm/" rel="external nofollow noopener" target="_blank">Synergy of Scientific and Machine Learning Modeling Workshop</a>, ICML 2023. </li> <li> <a href="https://arxiv.org/abs/2301.10343" rel="external nofollow noopener" target="_blank">ClimaX</a> has been featured in major media outlets, including <a href="https://www.washingtonpost.com/weather/2023/09/21/hurricane-lee-artificial-intelligence-forecasting/" rel="external nofollow noopener" target="_blank">Washington Post</a>, <a href="https://www.technologyreview.com/2023/11/14/1083366/google-deepminds-weather-ai-can-forecast-extreme-weather-quicker-and-more-accurately/" rel="external nofollow noopener" target="_blank">MIT Tech Review</a>, <a href="https://www.infoq.com/news/2023/03/microsoft-climate-ai/" rel="external nofollow noopener" target="_blank">InfoQ</a>, and <a href="https://www.nature.com/articles/d41586-024-00780-8" rel="external nofollow noopener" target="_blank">Nature</a>. </li> <li> Honored to receive the <a href="https://www.sciencehub.ucla.edu/2023-amazon-fellows/" rel="external nofollow noopener" target="_blank">Amazon Fellowship</a>. </li> <li> We released <a href="https://arxiv.org/abs/2301.10343" rel="external nofollow noopener" target="_blank">ClimaX</a> – the first foundation model for weather and climate. </li> <li> <a href="https://arxiv.org/abs/2207.04179" rel="external nofollow noopener" target="_blank">Transformer Neural Processes</a>, my first paper as a PhD student, got accepted at ICML 2022. </li> <li> Started my PhD at UCLA, working with <a href="https://aditya-grover.github.io/" rel="external nofollow noopener" target="_blank">Adtitya Grover</a>! </li> </ul> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#820000"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> </div> <div id="nguyen2024lico" class="col-sm-8"> <div class="title">LICO: Large language models for in-context molecular optimization</div> <div class="author"> <em>Tung Nguyen</em>, and <a href="https://aditya-grover.github.io/" rel="external nofollow noopener" target="_blank">Aditya Grover</a> </div> <div class="periodical"> <em>International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2406.18851" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=F9mgq3sAAAAJ&amp;citation_for_view=F9mgq3sAAAAJ:bEWYMUwI8FkC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-7-4285F4?logo=googlescholar&amp;labelColor=beige" alt="7 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Optimizing black-box functions is a fundamental problem in science and engineering. To solve this problem, many approaches learn a surrogate function that estimates the underlying objective from limited historical evaluations. Large Language Models (LLMs), with their strong pattern-matching capabilities via pretraining on vast amounts of data, stand out as a potential candidate for surrogate modeling. However, directly prompting a pretrained language model to produce predictions is not feasible in many scientific domains due to the scarcity of domain-specific data in the pretraining corpora and the challenges of articulating complex problems in natural language. In this work, we introduce LICO, a general-purpose model that extends arbitrary base LLMs for black-box optimization, with a particular application to the molecular domain. To achieve this, we equip the language model with a separate embedding layer and prediction layer, and train the model to perform in-context predictions on a diverse set of functions defined over the domain. Once trained, LICO can generalize to unseen molecule properties simply via in-context prompting. LICO achieves state-of-the-art performance on PMO, a challenging molecular optimization benchmark comprising over 20 objective functions.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0048BA"> <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> <span class="award badge rounded w-100"> Best Paper </span> </div> <div id="zhao2024probing" class="col-sm-8"> <div class="title">Probing the Decision Boundaries of In-context Learning in Large Language Models</div> <div class="author"> <a href="https://siyan-zhao.github.io/" rel="external nofollow noopener" target="_blank">Siyan Zhao</a>, <em>Tung Nguyen</em>, and <a href="https://aditya-grover.github.io/" rel="external nofollow noopener" target="_blank">Aditya Grover</a> </div> <div class="periodical"> <em>Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <span class="honor"> Best Paper Award, Foundation Model Interventions Workshop, NeurIPS 2024 </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/eb5dd4476448c44e55a759a985b3bbec-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/siyan-zhao/ICL_decision_boundary" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=F9mgq3sAAAAJ&amp;citation_for_view=F9mgq3sAAAAJ:iH-uZ7U-co4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Paper</p> </div> <div class="abstract hidden"> <p>In-context learning is an emergent paradigm in large language models (LLMs) that enables them to generalize to new tasks and domains by simply prompting these models with a few exemplars without explicit parameter updates. Many attempts have been made to understand in-context learning in LLMs as a function of model scale, pretraining data, and other factors. In this work, we propose a new mechanism to probe and understand in-context learning from the lens of decision boundaries for in-context binary classification. Decision boundaries are straightforward to visualize and provide important information about the qualitative behavior of the inductive biases of standard classifiers. To our surprise, we find that the decision boundaries learned by current LLMs in simple binary classification tasks are often irregularly non-smooth, regardless of task linearity. This paper investigates the factors influencing these decision boundaries and explores methods to enhance their generalizability. We assess various approaches, including training-free and fine-tuning methods for LLMs, the impact of model architecture, and the effectiveness of active prompting techniques for smoothing decision boundaries in a data-efficient manner. Our findings provide a deeper understanding of in-context learning dynamics and offer practical improvements for enhancing robustness and generalizability of in-context learning.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0048BA"> <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> <span class="award badge rounded w-100"> Best Paper </span> </div> <div id="nguyen2024scaling" class="col-sm-8"> <div class="title">Scaling transformer neural networks for skillful and reliable medium-range weather forecasting</div> <div class="author"> <em>Tung Nguyen</em>, Rohan Shah, Hritik Bansal, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Troy Arcomano, Romit Maulik, Rao Kotamarthi, Ian Foster, Sandeep Madireddy, Aditya Grover' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <span class="honor"> Best Paper Award, Tackling Climate Change with Machine Learning Workshop, ICLR 2024 </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/7f19b99e63762d20e9df91144056f1ee-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/tung-nd/stormer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=F9mgq3sAAAAJ&amp;citation_for_view=F9mgq3sAAAAJ:_Qo2XoVZTnwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-52-4285F4?logo=googlescholar&amp;labelColor=beige" alt="52 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Paper</p> </div> <div class="abstract hidden"> <p>Weather forecasting is a fundamental problem for anticipating and mitigating the impacts of climate change. Recently, data-driven approaches for weather forecasting based on deep learning have shown great promise, achieving accuracies that are competitive with operational systems. However, those methods often employ complex, customized architectures without sufficient ablation analysis, making it difficult to understand what truly contributes to their success. Here we introduce Stormer, a simple transformer model that achieves state-of-the art performance on weather forecasting with minimal changes to the standard transformer backbone. We identify the key components of Stormer through careful empirical analyses, including weather-specific embedding, randomized dynamics forecast, and pressure-weighted loss. At the core of Stormer is a randomized forecasting objective that trains the model to forecast the weather dynamics over varying time intervals. During inference, this allows us to produce multiple forecasts for a target lead time and combine them to obtain better forecast accuracy. On WeatherBench 2, Stormer performs competitively at short to medium-range forecasts and outperforms current methods beyond 7 days, while requiring orders-of-magnitude less training data and compute. Additionally, we demonstrate Stormer’s favorable scaling properties, showing consistent improvements in forecast accuracy with increases in model size and training tokens. Code and checkpoints are available at https://github.com/tung-nd/stormer.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0048BA"> <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> </div> <div id="nguyen2023expt" class="col-sm-8"> <div class="title">ExPT: Synthetic Pretraining for Few-Shot Experimental Design</div> <div class="author"> <em>Tung Nguyen</em>, Sudhanshu Agrawal, and <a href="https://aditya-grover.github.io/" rel="external nofollow noopener" target="_blank">Aditya Grover</a> </div> <div class="periodical"> <em>Neural Information Processing Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/8fab4407e1fe9006b39180525c0d323c-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/tung-nd/ExPT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=F9mgq3sAAAAJ&amp;citation_for_view=F9mgq3sAAAAJ:e5wmG9Sq2KIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-15-4285F4?logo=googlescholar&amp;labelColor=beige" alt="15 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Experimental design is a fundamental problem in many science and engineering fields. In this problem, sample efficiency is crucial due to the time, money, and safety costs of real-world design evaluations. Existing approaches either rely on active data collection or access to large, labeled datasets of past experiments, making them impractical in many real-world scenarios. In this work, we address the more challenging yet realistic setting of few-shot experimental design, where only a few labeled data points of input designs and their corresponding values are available. We approach this problem as a conditional generation task, where a model conditions on a few labeled examples and the desired output to generate an optimal input design. To this end, we introduce Experiment Pretrained Transformers (ExPT), a foundation model for few-shot experimental design that employs a novel combination of synthetic pretraining with in-context learning. In ExPT, we only assume knowledge of a finite collection of unlabelled data points from the input domain and pretrain a transformer neural network to optimize diverse synthetic functions defined over this domain. Unsupervised pretraining allows ExPT to adapt to any design task at test time in an in-context fashion by conditioning on a few labeled data points from the target task and generating the candidate optima. We evaluate ExPT on few-shot experimental design in challenging domains and demonstrate its superior generality and performance compared to existing methods. The source code is available at https://github.com/tung-nd/ExPT.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#4E6C50"> <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a> </abbr> <span class="award badge rounded w-100"> Best Paper </span> </div> <div id="nguyen2023climax" class="col-sm-8"> <div class="title">ClimaX: A foundation model for weather and climate</div> <div class="author"> <em>Tung Nguyen</em>, <a href="https://brandstetter-johannes.github.io/" rel="external nofollow noopener" target="_blank">Johannes Brandstetter</a>, <a href="https://scholar.google.com/citations?user=4D1n8scAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Ashish Kapoor</a>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jayesh K Gupta, Aditya Grover' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>International Conference on Machine Learning</em>, 2023 </div> <div class="periodical"> </div> <span class="honor"> Best Paper Award, Synergy of Scientific and Machine Learning Modeling Workshop, ICML 2023 </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2301.10343" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/microsoft/ClimaX" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=F9mgq3sAAAAJ&amp;citation_for_view=F9mgq3sAAAAJ:IWHjjKOFINEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-340-4285F4?logo=googlescholar&amp;labelColor=beige" alt="340 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Paper</p> </div> <div class="abstract hidden"> <p>Most state-of-the-art approaches for weather and climate modeling are based on physics-informed numerical models of the atmosphere. These approaches aim to model the non-linear dynamics and complex interactions between multiple variables, which are challenging to approximate. Additionally, many such numerical models are computationally intensive, especially when modeling the atmospheric phenomenon at a fine-grained spatial and temporal resolution. Recent data-driven approaches based on machine learning instead aim to directly solve a downstream forecasting or projection task by learning a data-driven functional mapping using deep neural networks. However, these networks are trained using curated and homogeneous climate datasets for specific spatiotemporal tasks, and thus lack the generality of numerical models. We develop and demonstrate ClimaX, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings. ClimaX extends the Transformer architecture with novel encoding and aggregation blocks that allow effective use of available compute while maintaining general utility. ClimaX is pre-trained with a self-supervised learning objective on climate datasets derived from CMIP6. The pre-trained ClimaX can then be fine-tuned to address a breadth of climate and weather tasks, including those that involve atmospheric variables and spatio-temporal scales unseen during pretraining. Compared to existing data-driven baselines, we show that this generality in ClimaX results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets. The source code is available at https://github.com/microsoft/ClimaX.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#4E6C50"> <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a> </abbr> </div> <div id="nguyen2022transformer" class="col-sm-8"> <div class="title">Transformer Neural Processes: Uncertainty-Aware Meta Learning Via Sequence Modeling</div> <div class="author"> <em>Tung Nguyen</em>, and <a href="https://aditya-grover.github.io/" rel="external nofollow noopener" target="_blank">Aditya Grover</a> </div> <div class="periodical"> <em>International Conference on Machine Learning</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2207.04179" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/tung-nd/TNP-pytorch" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=F9mgq3sAAAAJ&amp;citation_for_view=F9mgq3sAAAAJ:QIV2ME_5wuYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-130-4285F4?logo=googlescholar&amp;labelColor=beige" alt="130 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Neural Processes (NPs) are a popular class of approaches for meta-learning. Similar to Gaussian Processes (GPs), NPs define distributions over functions and can estimate uncertainty in their predictions. However, unlike GPs, NPs and their variants suffer from underfitting and often have intractable likelihoods, which limit their applications in sequential decision making. We propose Transformer Neural Processes (TNPs), a new member of the NP family that casts uncertainty-aware meta learning as a sequence modeling problem. We learn TNPs via an autoregressive likelihood-based objective and instantiate it with a novel transformer-based architecture. The model architecture respects the inductive biases inherent to the problem structure, such as invariance to the observed data points and equivariance to the unobserved points. We further investigate knobs within the TNP framework that tradeoff expressivity of the decoding distribution with extra computation. Empirically, we show that TNPs achieve state-of-the-art performance on various benchmark problems, outperforming all previous NP variants on meta regression, image completion, contextual multi-armed bandits, and Bayesian optimization.</p> </div> </div> </div> </li> </ol> </div> <h2> <a href="/publications/" style="color: inherit">Selected Preprints</a> </h2> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> </div> <div id="nguyen2024predicting" class="col-sm-8"> <div class="title">Predicting from Strings: Language Model Embeddings for Bayesian Optimization</div> <div class="author"> <em>Tung Nguyen</em>, Qiuyi Zhang, Bangding Yang, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Chansoo Lee, Jorg Bornschein, Yingjie Miao, Sagi Perel, Yutian Chen, Xingyou Song' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>Under Review</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2410.10190" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/google-research/optformer/tree/main/optformer/embed_then_regress" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=F9mgq3sAAAAJ&amp;citation_for_view=F9mgq3sAAAAJ:HoB7MX3m0LUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Bayesian Optimization is ubiquitous in the field of experimental design and blackbox optimization for improving search efficiency, but has been traditionally restricted to regression models which are only applicable to fixed search spaces and tabular input features. We propose Embed-then-Regress, a paradigm for applying in-context regression over string inputs, through the use of string embedding capabilities of pretrained language models. By expressing all inputs as strings, we are able to perform general-purpose regression for Bayesian Optimization over various domains including synthetic, combinatorial, and hyperparameter optimization, obtaining comparable results to state-of-the-art Gaussian Process-based algorithms. Code can be found at https://github.com/google-research/optformer/tree/main/optformer/embed_then_regress.</p> </div> </div> </div> </li></ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%74%75%6E%67%6E%64@%63%73.%75%63%6C%61.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/tung-nd" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/tung-nguyen-40703616b" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=F9mgq3sAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/tungnd_13" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> <div style="text-align: center; margin-top: 2rem;"> <em>This webpage was adapted from my friend's webpage at <a href="https://khainb.com/" target="_blank" rel="external nofollow noopener">https://khainb.com/</a></em> </div> </article> </div> </div> <div style="display: flex; justify-content: center; align-items: center; margin-top: 2rem;"> <div style="width: 350px; height: 350px;"> <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QfASJALyoSA-_7UuZ6rbtw7GKsNCCnYpwOdkMbr9n4g"></script> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Tung Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>